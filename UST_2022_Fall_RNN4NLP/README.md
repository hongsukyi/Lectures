#Artificial Intelligence â€“ Deep Learning based Text Processing (2022 Fall)  
## Introduction to Recurrent Neural Network 

## Course Information
- The students can understand basic knowledge on deep learning specialized for text processing and make interesting and simple AI applications such as text classifiers.
- Principal knowledge on machine learning and deep learning
- Main characteristics about FCN, CNN, and RNN
- Characteristics about text data
- Deep learning architecture for text data analysis
### Instructor
- Hongsuk Yi 
### Time and Location
-  TUE 10:00 AM (UST Lecture room at KISTI)
## Materials  Deep Learning with Tensorflow 2 and Keras (Second Edition, Packt Pub.) (https://www.packtpub.com/product/deep-learning-with-tensorflow-2-and-keras/9781838823412)


## Syllabus
Event|Date|In-class lecture|Materials and Assignments
|---------|----|-------------|------------|
Lecture 1|-|Basic knowledge of NLP  |MG Hwang | 
Lecture 2|-|Word Embedding Theory |MG Hwang | 
Lecture 3|-|Word Embedding - Practice 1| MG Hwang | 
Lecture 4|-|Word Embedding - Practice 2 | MG Hwang | 
Lecture 5|-|The concept of machine learning and deep learning | MH Lee | 
Lecture 6|-|Understanding regression problems with FCN| MH Lee | 
Lecture 7|-|Understanding classification problems with FCN | MH Lee | 
Lecture 8|-|Text Analysis Practice with FCN | MH Leem | 
Lecture 9|11/01|Introduction to Recurrent Neural Network  | Prof. Hongsuk Yi| 
Lecture 10|11/08|Introduction to Long-Short Term Memroy | Prof. Hongsuk Yi | 
Lecture 11|11/15|Text generation with RNN  |Prof. Hongsuk Yi | 
Lecture 12|11/22|Sequence to Sequence model with RNN |Prof. Hongsuk Yi | 
Lecture 13|-|CNN Model based Feature Extraction| R Lee| 
Lecture 14|-|Text Classification based on CNN Model | R Lee| 
Lecture 15|-|Further Applications of Text Classification  | R Lee | 
Lecture 16|-|Final Exam |R Lee| 


## Reading list for further discussion
  
### Recurrent Neural Networks
- 

### Attention and Transformers

- [Attention] <a href=https://arxiv.org/pdf/1706.03762.pdf> Attention is All You Need</a>, In Proceedings of NeurIPS 2017  
  
- [BERT] <a href=https://www.aclweb.org/anthology/N19-1423> BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>, In Proceedings of ACL 2019

  ### Generative Adversarial Networks  
  
- [Original GAN] <a href="https://arxiv.org/pdf/1406.2661.pdf"> Generative Adversarial Networks</a>, Goodfellow et al. (2014)
- [StyleGAN] <a href="https://arxiv.org/pdf/1812.04948.pdf"> A Style-Based Generator Architecture for Generative Adversarial Networks</a>  Karras et al. (2019).
 

  ### Deep Reinforcement Learning           
- Deep Q-Learning
  - [DQN] <a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"> Playing Atari with Deep Reinforcement Learning</a>, arXiv preprint arXiv:1312.5602  
  - [PER] <a href="https://arxiv.org/pdf/1511.05952.pdf"> Prioritized Experience Replay</a> arXiv preprint arXiv:1511.05952 (2015) 
  - [Dueling DQN] <a href="https://arxiv.org/pdf/1511.06581.pdf"> Dueling Network Architectures for Deep Reinforcement Learning</a> arXiv:1511.06581 (2015).  
  - [Double DQN] <a href="https://arxiv.org/pdf/1509.06461.pdf">  Deep Reinforcement Learning with Double Q-Learning</a> (2015)  
  - [Rainbow DQN] <a href="https://arxiv.org/pdf/1710.02298.pdf"> Rainbow: Combining Improvements in Deep Reinforcement Learning</a> arXiv:1710.02298 (2017).  
- Policy Gradient and  Deterministic Policy Gradients    
  - [A3C] < a href="https://arxiv.org/pdf/1602.01783.pdf"> Asynchronous Methods for Deep Reinforcement Learning</a> Mnih et al, 2016.  
  - [DPG] < a href="http://proceedings.mlr.press/v32/silver14.pdf"> Deterministic Policy Gradient Algorithms</a> Silver et al, 2014  
  - [DDPG] < a href="https://arxiv.org/pdf/1509.02971.pdf"> Continuous Control With Deep Reinforcement Learning</a> Lillicrap et al, 2015
