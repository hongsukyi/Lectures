{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 멀티클래스에 interpret를 추가하고 VQC(output_shape=num_classes) \n",
    "1. output_shape = num_classes\n",
    "2. interpret = index% num_classes\n",
    "3. feature=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import qiskit\n",
    "import tensorflow \n",
    "import platform\n",
    "\n",
    "datetime.datetime.now()\n",
    "\n",
    "print('qiskit version:', qiskit.__version__)\n",
    "print('tf     version:', tensorflow.__version__)\n",
    "print('Python Version:',platform.python_version())\n",
    "print('OS            :', platform.system())\n",
    "print('코딩시간       :', time.strftime(\"%a %b %d %H:%M:%S %Y %Z\"))\n",
    "print('Copyright     : Hongsuk (hongsuk.yi@gmail.com)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, accuracy_score,classification_report\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 포팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.utils import algorithm_globals\n",
    "from qiskit_machine_learning.optimizers import SPSA, L_BFGS_B, COBYLA\n",
    "from qiskit_machine_learning.algorithms import VQC, QSVC, NeuralNetworkClassifier \n",
    "\n",
    "from qiskit.primitives import Sampler\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes, ZFeatureMap, EfficientSU2, TwoLocal\n",
    "from qiskit_machine_learning.circuit.library import QNNCircuit\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_machine_learning.exceptions import QiskitMachineLearningError\n",
    "from qiskit_machine_learning.utils import algorithm_globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv(\"https://raw.githubusercontent.com/hongsukyi/Lectures/main/data/vds16_L3_5m_Days20.csv\")\n",
    "#df = pd.read_csv(\"./vds16_L3_120m_Days20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 라벨별 샘풀링 개수 : 200개\n",
    "sample_per_label = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#각 라벨별로 200개씩 샘플링\n",
    "df = df_orig.groupby('label').apply(lambda x: x.sample(n=sample_per_label, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 결과 확인\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas plot을 사용하여 bar chart 그리기\n",
    "label_counts.plot(kind='bar', title='Number of Samples per Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=0) # x축 라벨 회전 (필요에 따라 조절)\n",
    "plt.tight_layout() # 레이아웃 조정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df, x = 'ToVol', y = 'Speed', hue='label') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot( x = 'rho', y = 'Speed', hue='label', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical SVM\n",
    "X = df[['ToVol', 'Speed','Hour','rho' ]]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "print(X_scaled.shape)\n",
    "print(X_scaled[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_enc = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_enc, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2F=X_test[:, :2]\n",
    "X_test2F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of SVM\n",
    "def cm_analysis(y_true, y_pred, labels, ymap=None, figsize=(5,4)): \n",
    "    if ymap is not None: \n",
    "        y_pred = [ymap[yi] for yi in y_pred] \n",
    "        y_true = [ymap[yi] for yi in y_true] \n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels) \n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True) \n",
    "    cm_perc = cm / cm_sum.astype(float) * 100 \n",
    "    annot = np.empty_like(cm).astype(str) \n",
    "    nrows, ncols = cm.shape \n",
    "    for i in range(nrows): \n",
    "        for j in range(ncols): \n",
    "            c = cm[i, j] \n",
    "            p = cm_perc[i, j] \n",
    "            if i == j: \n",
    "                s = cm_sum[i] \n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s) \n",
    "            elif c == 0: \n",
    "                annot[i, j] = '' \n",
    "            else: \n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels) \n",
    "    cm.index.name = 'Actual' \n",
    "    cm.columns.name = 'Predicted' \n",
    "    fig, ax = plt.subplots(figsize=figsize) \n",
    "    sns.heatmap(cm, annot=annot, fmt='', ax=ax) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_sv=0.0\n",
    "acc_ann=0.0\n",
    "acc_dnn=0.0\n",
    "acc_qsvc=0.0\n",
    "acc_vqc=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create svm Classifier\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "a_svm =  model.score(X_test,y_test) \n",
    "result.append(a_svm) \n",
    "print(\"Test accuracy_score:%.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Confustion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " cm_analysis(y_test, y_pred, labels=None, ymap=None, figsize=(8,5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_test2F, y_test)\n",
    "\n",
    "plot_decision_regions(X_test2F, y_test, clf=model)\n",
    "plt.xlabel('Traffic Volume')\n",
    "plt.ylabel('Traffic Speed')\n",
    "plt.title('SVM Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical QNN \n",
    "model= MLPClassifier(max_iter=1000,  random_state=5)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "a_ann =  model.score(X_test,y_test) \n",
    "result.append(a_ann) \n",
    "print(\"Test accuracy_score:%.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Confustion Matrix:\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_analysis(y_test, y_pred,labels=None, ymap=None, figsize=(8,6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_test2F, y_test)\n",
    "plot_decision_regions(X_test2F, y_test, clf=model)\n",
    "plt.xlabel('Occupancy')\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.title('ANN Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y.nunique()\n",
    "num_features = X_train.shape[1]\n",
    "print('특성 개수  :',num_features)\n",
    "print(f\"클래스 개수: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_dim=num_features, activation = 'relu'),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(num_classes, activation= 'softmax')])  \n",
    "\n",
    "dnn2F = Sequential([\n",
    "    Dense(64, input_dim= 2, activation = 'relu'),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dense(num_classes, activation= 'softmax')])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train, epochs=50, batch_size=32, validation_split=0.2,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, a_dnn = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of DNN:%.4f\"%a_dnn)\n",
    "result.append(a_dnn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train_loss', color='blue')\n",
    "plt.plot(history.history['val_loss'], label='val_loss', color='red')\n",
    "\n",
    "# 현재 axes 객체 가져오기\n",
    "ax1 = plt.gca()\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "\n",
    "# x축을 공유하는 새로운 axes 객체 생성 (오른쪽 y축)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(history.history['accuracy'], label='train_accuracy', color='green')\n",
    "ax2.plot(history.history['val_accuracy'], label='val_accuracy', color='lime')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "\n",
    "# 범례를 명시적으로 처리 (두 개의 axes에 대한 라벨을 합치기)\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines1 + lines2, labels1 + labels2, loc='center right')\n",
    "\n",
    "plt.title('Model Training History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Onehot2Int(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return np.argmax(y_pred, axis=1)   \n",
    "\n",
    "model =Onehot2Int(dnn2F)\n",
    "\n",
    "ax=plot_decision_regions(X_test2F, y_test, clf=model)\n",
    "plt.xlabel('Traffic Volume')\n",
    "plt.ylabel('Traffic Speed')\n",
    "plt.title('DNN : Decision Boundary')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "if num_classes == 3 : \n",
    "    ax.legend(handles, ['Fast', 'Show', 'Jam'],  framealpha=0.3, scatterpoints=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Simulator for Quantum Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from qiskit_machine_learning.algorithms import QSVC, VQC\n",
    "from qiskit.circuit.library import ZZFeatureMap,  RealAmplitudes\n",
    "from qiskit_machine_learning.optimizers import COBYLA\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_machine_learning.state_fidelities import ComputeUncompute\n",
    "from qiskit.primitives import StatevectorSampler as Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) VQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature map\n",
    "- from classical data to qubit through data encoding, data embedding, data loading\n",
    "- The most standard fearture is ZZFeatureMap\n",
    "\n",
    "ansatz\n",
    "\n",
    "- apply a parameterize quantum circuit.\n",
    "- objective function characterized the distance between the prediction and known labeled data.\n",
    "- A parametrized quantum circuit is call a paramenterized trial state, variational form, or ansatz.- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수정할 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = ZZFeatureMap(feature_dimension = num_features , reps=1, entanglement=\"linear\")\n",
    "ansatz = RealAmplitudes(num_qubits = num_features , reps=1, entanglement=\"linear\")\n",
    "#ansatz.decompose().draw(output=\"mpl\", style=\"clifford\", fold=20)\n",
    "#ansatz.decompose().draw(output=\"mpl\", style=\"clifford\", fold=20)\n",
    "#feature_map.decompose().draw(output=\"mpl\", fold=20)   #style=\"clifford\",  fold=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StatevectorSampler를 이용한 Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Sampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_interpret(measured_integer):\n",
    "    \"\"\"측정된 정수를 num_classes으로 나눈 나머지를 클래스 인덱스로 반환\"\"\"\n",
    "    return measured_integer % num_classes\n",
    "    \n",
    "# callback function that draws a live plot when the .fit() method is called\n",
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onh-hot encoded format의 경우 crossEntropyLoss를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.optimizers import COBYLA, L_BFGS_B, ADAM, SLSQP, AQGD\n",
    "optimizer = COBYLA(maxiter=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "\n",
    "vqc = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer,\n",
    "    callback=callback_graph,\n",
    "    output_shape=num_classes,\n",
    "    interpret=multi_class_interpret  # interpret 함수 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "import time\n",
    "# clear objective value history\n",
    "\n",
    "objective_func_vals = []\n",
    "start = time.time()\n",
    "vqc.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Training time: {round(elapsed)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(objective_func_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_q4 = vqc.score(X_train, y_train)\n",
    "a_vqc = vqc.score(X_test, y_test)\n",
    "\n",
    "print(f\"Quantum VQC on the training dataset: {train_score_q4:.2f}\")\n",
    "print(f\"Quantum VQC on the test dataset    : {a_vqc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VQC performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = vqc.predict(X_test)\n",
    "\n",
    "# print classification report and confusion matrix for the classifier\n",
    "print(\"Classification report: \\n\", metrics.classification_report(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = vqc.predict(X_test)\n",
    "print(f\"Predicted labels: {predict}\")\n",
    "print(f\"Ground truth:     {y_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'models': ['SVC', 'ANN','DNN', 'VQC'],\n",
    "    'accuracy':[a_svm, a_ann, a_dnn,  a_vqc]})\n",
    "df=df.sort_values(by='accuracy', ascending=True)\n",
    "\n",
    "df.plot.bar(x='models',y='accuracy',rot=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_qsvc = ZZFeatureMap(feature_dimension=X_train.shape[1], reps=2, entanglement=\"linear\")\n",
    "fm_qsvc.decompose().draw(output=\"mpl\", style=\"clifford\", fold=20)\n",
    "sampler = Sampler()\n",
    "fidelity = ComputeUncompute(sampler=sampler)\n",
    "qsvc_kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=fm_qsvc)\n",
    "qsvc = QSVC(quantum_kernel=qsvc_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "qsvc.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "print(f\"Training time: {round(elapsed)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_qsvc = qsvc.score(X_test, y_test)\n",
    "print(f\"QSVC classification test score: {a_qsvc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'models': ['SVC', 'ANN','DNN','Q_SVC', 'Q_VQC'],\n",
    "    'accuracy':[acc_svc, acc_ann, acc_dnn, acc_qsvc, acc_vqc]})\n",
    "df=df.sort_values(by='accuracy', ascending=True)\n",
    "\n",
    "df.plot.bar(x='models',y='accuracy',rot=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report of QSVC\n",
    "y_pred = qsvc.predict(X_test) \n",
    "metrics.classification_report(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_QISKIT",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
